{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXKwG66tx9faTvBhduzaAz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sureshrgmi/LandTech--Suresh-Regmi/blob/main/Q3%20-%20Sourcing%20Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code shows how to gather data from a specific API (PlanHat in this case), Load it into pandas dataframe, perform transformation if necessary and finally load them to a Redshift data warehouse. The process follows these simple stps and contains placeholders instead of actual credentials which could be changed based on the environment you are working on.\n",
        "\n",
        "\n",
        "Steps\n",
        "\n",
        "1. Import necessary libraries such as requests, pandas, psycopg2\n",
        "2. Define variables for the api url, api token (if necessary), endpoint you want to work with and database credentials.\n",
        "3. Get the data from the API and load it into pandas dataframe\n",
        "4. Perform exploartory analysis and data transformation on the reponse data in the dataframe (I prefer performing this task at the later stage using SQL once the data is loaded into the database/warehouse)\n",
        "5. Load the data into the data warehouse utilizing the credentials"
      ],
      "metadata": {
        "id": "nXaU-_Sv1RNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qENC4KQ98SaR"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "\n",
        "# PlanHat API credentials and endpoints\n",
        "planhat_api_url = 'https://api.planhat.com/v1/'\n",
        "planhat_api_token = 'YOUR_PLANHAT_API_TOKEN'  # Replace with your PlanHat API token\n",
        "\n",
        "# Redshift database credentials\n",
        "redshift_host = 'YOUR_REDSHIFT_HOST'  # Replace this with the hostname/url\n",
        "redshift_port = '5439'  # Using default port here\n",
        "redshift_db = 'YOUR_REDSHIFT_DB'  # Replace this with the database name\n",
        "redshift_user = 'YOUR_REDSHIFT_USER'  # Redshift username\n",
        "redshift_password = 'YOUR_REDSHIFT_PASSWORD'  # Redshift password\n",
        "\n",
        "# Define the API endpoint for the PlanHat data you want to get\n",
        "planhat_endpoint = 'YOUR_PLANHAT_ENDPOINT'  # Replace this with the specific endpoint you want to get\n",
        "\n",
        "# Make an API request to PlanHat\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {planhat_api_token}'\n",
        "}\n",
        "\n",
        "response = requests.get(planhat_api_url + planhat_endpoint, headers=headers)\n",
        "\n",
        "# Check if the API request was successful\n",
        "if response.status_code == 200:\n",
        "    # Convert the JSON response to a Pandas DataFrame\n",
        "    data = response.json()\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # We can do the data transformation using libraries such as Pandas and NumPy\n",
        "    # Personally, I prefer loading this data into database table as it is and\n",
        "    # performing the data transformation there\n",
        "\n",
        "    # Connect to Redshift\n",
        "    conn = psycopg2.connect(\n",
        "        host=redshift_host,\n",
        "        port=redshift_port,\n",
        "        dbname=redshift_db,\n",
        "        user=redshift_user,\n",
        "        password=redshift_password\n",
        "    )\n",
        "\n",
        "    # Create a cursor\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Define the Redshift table where you want to insert the data\n",
        "    redshift_table_name = 'YOUR_REDSHIFT_TABLE'  # Replace with the actual table name\n",
        "\n",
        "    # Inserting data into the Redshift table\n",
        "    df.to_sql(name=redshift_table_name, con=conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Commit the transaction and close the cursor and connection\n",
        "    conn.commit()\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "\n",
        "    print(f'Data successfully loaded into Redshift table: {redshift_table_name}')\n",
        "else:\n",
        "    print(f'Error: Unable to fetch data from PlanHat API. Status code: {response.status_code}')\n"
      ]
    }
  ]
}